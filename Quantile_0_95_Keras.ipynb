{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lbu9efRrm8rB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_bFybhox26tc"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLp6mSkQm9ZS",
    "outputId": "14a2d2bd-86fb-496c-b241-26629e4ed6ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "stock='AXISBANK.NS'\n",
    "data = yf.download(stock,'2005-01-01','2023-05-05')\n",
    "data1=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "re200cTwnAnm",
    "outputId": "5ebddc1d-450e-42b2-f95a-e470b37a6438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2005-01-03    0.002702\n",
       "2005-01-04    0.002610\n",
       "2005-01-05    0.001597\n",
       "2005-01-06    0.001764\n",
       "2005-01-07    0.002684\n",
       "                ...   \n",
       "2023-04-27    0.913188\n",
       "2023-04-28    0.890224\n",
       "2023-05-02    0.901652\n",
       "2023-05-03    0.890063\n",
       "2023-05-04    0.896609\n",
       "Name: Adj Close, Length: 4525, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_prices = data['Adj Close']\n",
    "\n",
    "min_value = close_prices.min()\n",
    "max_value = close_prices.max()\n",
    "normalized_data = (close_prices - min_value) / (max_value - min_value)\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2005-01-03  0.001788  0.001671  0.003257  0.003139   0.002702  0.011789\n",
      "2005-01-04  0.003101  0.001886  0.003692  0.003031   0.002610  0.009257\n",
      "2005-01-05  0.002854  0.001446  0.001640  0.001855   0.001597  0.009649\n",
      "2005-01-06  0.001594  0.001457  0.001520  0.002049   0.001764  0.009894\n",
      "2005-01-07  0.000851  0.001864  0.002313  0.003117   0.002684  0.012695\n",
      "...              ...       ...       ...       ...        ...       ...\n",
      "2023-04-27  0.918162  0.914288  0.915852  0.912745   0.913188  0.132671\n",
      "2023-04-28  0.915039  0.914342  0.889957  0.889664   0.890224  0.190839\n",
      "2023-05-02  0.898779  0.899717  0.901466  0.901151   0.901652  0.107415\n",
      "2023-05-03  0.892156  0.889485  0.890391  0.889502   0.890063  0.125293\n",
      "2023-05-04  0.888011  0.889807  0.894137  0.896082   0.896609  0.080938\n",
      "\n",
      "[4525 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "columns_to_normalize = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "min_values = data[columns_to_normalize].min()\n",
    "max_values = data[columns_to_normalize].max()\n",
    "normalized_data = (data[columns_to_normalize] - min_values) / (max_values - min_values)\n",
    "print(normalized_data)\n",
    "data=normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PmtwEW1-_kRv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.011789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.009257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.009649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.009894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.012695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>0.918162</td>\n",
       "      <td>0.914288</td>\n",
       "      <td>0.915852</td>\n",
       "      <td>0.912745</td>\n",
       "      <td>0.913188</td>\n",
       "      <td>0.132671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>0.915039</td>\n",
       "      <td>0.914342</td>\n",
       "      <td>0.889957</td>\n",
       "      <td>0.889664</td>\n",
       "      <td>0.890224</td>\n",
       "      <td>0.190839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>0.898779</td>\n",
       "      <td>0.899717</td>\n",
       "      <td>0.901466</td>\n",
       "      <td>0.901151</td>\n",
       "      <td>0.901652</td>\n",
       "      <td>0.107415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>0.892156</td>\n",
       "      <td>0.889485</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.889502</td>\n",
       "      <td>0.890063</td>\n",
       "      <td>0.125293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>0.888011</td>\n",
       "      <td>0.889807</td>\n",
       "      <td>0.894137</td>\n",
       "      <td>0.896082</td>\n",
       "      <td>0.896609</td>\n",
       "      <td>0.080938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4525 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume\n",
       "Date                                                                   \n",
       "2005-01-03  0.001788  0.001671  0.003257  0.003139   0.002702  0.011789\n",
       "2005-01-04  0.003101  0.001886  0.003692  0.003031   0.002610  0.009257\n",
       "2005-01-05  0.002854  0.001446  0.001640  0.001855   0.001597  0.009649\n",
       "2005-01-06  0.001594  0.001457  0.001520  0.002049   0.001764  0.009894\n",
       "2005-01-07  0.000851  0.001864  0.002313  0.003117   0.002684  0.012695\n",
       "...              ...       ...       ...       ...        ...       ...\n",
       "2023-04-27  0.918162  0.914288  0.915852  0.912745   0.913188  0.132671\n",
       "2023-04-28  0.915039  0.914342  0.889957  0.889664   0.890224  0.190839\n",
       "2023-05-02  0.898779  0.899717  0.901466  0.901151   0.901652  0.107415\n",
       "2023-05-03  0.892156  0.889485  0.890391  0.889502   0.890063  0.125293\n",
       "2023-05-04  0.888011  0.889807  0.894137  0.896082   0.896609  0.080938\n",
       "\n",
       "[4525 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "73fqShMpnDN4"
   },
   "outputs": [],
   "source": [
    "returns = np.diff(data['Adj Close'])\n",
    "copyreturns=np.diff(data1['Adj Close'])\n",
    "copyreturns=-copyreturns\n",
    "returns=-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmZHg_p26ahP",
    "outputId": "863d1809-a9dd-434c-bfe3-8d917b951075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4525, 6), (4524,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape,returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMgvQUgA6dIw",
    "outputId": "cc119b57-0440-4688-9ef4-f3b6abc64c88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4524,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcFGmyFC4COW",
    "outputId": "78a22ef4-33bc-4a28-d774-b1b63fbf2934"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.893906364218827"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwV_2pdNnGx4",
    "outputId": "da362001-3831-41d9-f4f3-ae6878067783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2005-01-03    0.002702\n",
       "2005-01-04    0.002610\n",
       "2005-01-05    0.001597\n",
       "2005-01-06    0.001764\n",
       "2005-01-07    0.002684\n",
       "                ...   \n",
       "2023-04-27    0.913188\n",
       "2023-04-28    0.890224\n",
       "2023-05-02    0.901652\n",
       "2023-05-03    0.890063\n",
       "2023-05-04    0.896609\n",
       "Name: Adj Close, Length: 4525, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5AvfkJoquFc",
    "outputId": "f87d37b9-c191-4a09-a97d-6b9aec246cee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00019759203453112887, 0.009668437226715202)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(returns)\n",
    "std_dev = np.std(returns)\n",
    "mean,std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcFxz8yIQ9qM",
    "outputId": "f67ab73b-6928-41bd-d852-d4310e93e869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.28627670e-05,  1.01224887e-03, -1.67154211e-04, ...,\n",
       "       -1.14283347e-02,  1.15892602e-02, -6.54576884e-03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It97f7V1RXDk",
    "outputId": "a063e301-0f1c-4c9c-9e1c-f68cdb41bf78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08373769, -0.07999808, -0.06792978, ...,  0.06450116,\n",
       "        0.08153718,  0.12803811])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.array(returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OXFADha_A2lN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JZwcIuXCzw-q"
   },
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, y_p):\n",
    "        e = y-y_p\n",
    "        return tf.keras.backend.mean(tf.keras.backend.maximum(q*e, (q-1)*e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xXLu5K8-lwxJ"
   },
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', input_dim=1))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "suD-Bi98mSCa"
   },
   "outputs": [],
   "source": [
    "quantile = 0.95\n",
    "model.compile(optimizer='adam', loss=lambda y, y_p: quantile_loss(quantile, y, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmdir21AmqMz",
    "outputId": "0c6d448f-cc2a-4fc6-d822-255070cf2f0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4524,), (4524,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=data['Adj Close'][0:-1]\n",
    "input.shape,returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtaQv5dAmt5u",
    "outputId": "351b2428-ca76-47ca-aadd-51a07d843866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "142/142 [==============================] - 1s 910us/step - loss: 0.0013\n",
      "Epoch 2/100\n",
      "142/142 [==============================] - 0s 857us/step - loss: 0.0011\n",
      "Epoch 3/100\n",
      "142/142 [==============================] - 0s 842us/step - loss: 0.0010\n",
      "Epoch 4/100\n",
      "142/142 [==============================] - 0s 837us/step - loss: 0.0010\n",
      "Epoch 5/100\n",
      "142/142 [==============================] - 0s 832us/step - loss: 0.0010\n",
      "Epoch 6/100\n",
      "142/142 [==============================] - 0s 862us/step - loss: 0.0010\n",
      "Epoch 7/100\n",
      "142/142 [==============================] - 0s 842us/step - loss: 0.0010\n",
      "Epoch 8/100\n",
      "142/142 [==============================] - 0s 964us/step - loss: 0.0010\n",
      "Epoch 9/100\n",
      "142/142 [==============================] - 0s 881us/step - loss: 9.8424e-04\n",
      "Epoch 10/100\n",
      "142/142 [==============================] - 0s 866us/step - loss: 0.0010\n",
      "Epoch 11/100\n",
      "142/142 [==============================] - 0s 864us/step - loss: 9.9612e-04\n",
      "Epoch 12/100\n",
      "142/142 [==============================] - 0s 851us/step - loss: 9.9077e-04\n",
      "Epoch 13/100\n",
      "142/142 [==============================] - 0s 844us/step - loss: 9.9057e-04\n",
      "Epoch 14/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 9.9633e-04\n",
      "Epoch 15/100\n",
      "142/142 [==============================] - 0s 920us/step - loss: 9.8718e-04\n",
      "Epoch 16/100\n",
      "142/142 [==============================] - 0s 869us/step - loss: 9.9194e-04\n",
      "Epoch 17/100\n",
      "142/142 [==============================] - 0s 867us/step - loss: 9.7980e-04\n",
      "Epoch 18/100\n",
      "142/142 [==============================] - 0s 981us/step - loss: 0.0010\n",
      "Epoch 19/100\n",
      "142/142 [==============================] - 0s 883us/step - loss: 9.8522e-04\n",
      "Epoch 20/100\n",
      "142/142 [==============================] - 0s 960us/step - loss: 9.7749e-04\n",
      "Epoch 21/100\n",
      "142/142 [==============================] - 0s 932us/step - loss: 9.8058e-04\n",
      "Epoch 22/100\n",
      "142/142 [==============================] - 0s 858us/step - loss: 9.8050e-04\n",
      "Epoch 23/100\n",
      "142/142 [==============================] - 0s 898us/step - loss: 9.8392e-04\n",
      "Epoch 24/100\n",
      "142/142 [==============================] - 0s 838us/step - loss: 9.6833e-04\n",
      "Epoch 25/100\n",
      "142/142 [==============================] - 0s 842us/step - loss: 9.7672e-04\n",
      "Epoch 26/100\n",
      "142/142 [==============================] - 0s 934us/step - loss: 9.9266e-04\n",
      "Epoch 27/100\n",
      "142/142 [==============================] - 0s 844us/step - loss: 9.8879e-04\n",
      "Epoch 28/100\n",
      "142/142 [==============================] - 0s 852us/step - loss: 9.9106e-04\n",
      "Epoch 29/100\n",
      "142/142 [==============================] - 0s 839us/step - loss: 9.9011e-04\n",
      "Epoch 30/100\n",
      "142/142 [==============================] - 0s 831us/step - loss: 9.7427e-04\n",
      "Epoch 31/100\n",
      "142/142 [==============================] - 0s 878us/step - loss: 9.7404e-04\n",
      "Epoch 32/100\n",
      "142/142 [==============================] - 0s 850us/step - loss: 9.7293e-04\n",
      "Epoch 33/100\n",
      "142/142 [==============================] - 0s 847us/step - loss: 9.7468e-04\n",
      "Epoch 34/100\n",
      "142/142 [==============================] - 0s 838us/step - loss: 9.9760e-04\n",
      "Epoch 35/100\n",
      "142/142 [==============================] - 0s 834us/step - loss: 9.9423e-04\n",
      "Epoch 36/100\n",
      "142/142 [==============================] - 0s 966us/step - loss: 9.8656e-04\n",
      "Epoch 37/100\n",
      "142/142 [==============================] - 0s 877us/step - loss: 9.8559e-04\n",
      "Epoch 38/100\n",
      "142/142 [==============================] - 0s 840us/step - loss: 9.8392e-04\n",
      "Epoch 39/100\n",
      "142/142 [==============================] - 0s 853us/step - loss: 9.7787e-04\n",
      "Epoch 40/100\n",
      "142/142 [==============================] - 0s 871us/step - loss: 9.7765e-04\n",
      "Epoch 41/100\n",
      "142/142 [==============================] - 0s 838us/step - loss: 9.7562e-04\n",
      "Epoch 42/100\n",
      "142/142 [==============================] - 0s 859us/step - loss: 9.6623e-04\n",
      "Epoch 43/100\n",
      "142/142 [==============================] - 0s 833us/step - loss: 9.7084e-04\n",
      "Epoch 44/100\n",
      "142/142 [==============================] - 0s 826us/step - loss: 9.7660e-04\n",
      "Epoch 45/100\n",
      "142/142 [==============================] - 0s 854us/step - loss: 9.7378e-04\n",
      "Epoch 46/100\n",
      "142/142 [==============================] - 0s 918us/step - loss: 9.7035e-04\n",
      "Epoch 47/100\n",
      "142/142 [==============================] - 0s 870us/step - loss: 9.7097e-04\n",
      "Epoch 48/100\n",
      "142/142 [==============================] - 0s 871us/step - loss: 9.7824e-04\n",
      "Epoch 49/100\n",
      "142/142 [==============================] - 0s 837us/step - loss: 9.7296e-04\n",
      "Epoch 50/100\n",
      "142/142 [==============================] - 0s 859us/step - loss: 9.7736e-04\n",
      "Epoch 51/100\n",
      "142/142 [==============================] - 0s 863us/step - loss: 9.7261e-04\n",
      "Epoch 52/100\n",
      "142/142 [==============================] - 0s 855us/step - loss: 9.6396e-04\n",
      "Epoch 53/100\n",
      "142/142 [==============================] - 0s 841us/step - loss: 9.6561e-04\n",
      "Epoch 54/100\n",
      "142/142 [==============================] - 0s 901us/step - loss: 9.6862e-04\n",
      "Epoch 55/100\n",
      "142/142 [==============================] - 0s 893us/step - loss: 9.7058e-04\n",
      "Epoch 56/100\n",
      "142/142 [==============================] - 0s 858us/step - loss: 9.6505e-04\n",
      "Epoch 57/100\n",
      "142/142 [==============================] - 0s 860us/step - loss: 9.7529e-04\n",
      "Epoch 58/100\n",
      "142/142 [==============================] - 0s 831us/step - loss: 9.6610e-04\n",
      "Epoch 59/100\n",
      "142/142 [==============================] - 0s 1ms/step - loss: 9.6810e-04\n",
      "Epoch 60/100\n",
      "142/142 [==============================] - 0s 994us/step - loss: 9.7819e-04\n",
      "Epoch 61/100\n",
      "142/142 [==============================] - 0s 906us/step - loss: 9.6969e-04\n",
      "Epoch 62/100\n",
      "142/142 [==============================] - 0s 933us/step - loss: 9.7185e-04\n",
      "Epoch 63/100\n",
      "142/142 [==============================] - 0s 839us/step - loss: 9.7126e-04\n",
      "Epoch 64/100\n",
      "142/142 [==============================] - 0s 848us/step - loss: 9.6232e-04\n",
      "Epoch 65/100\n",
      "142/142 [==============================] - 0s 921us/step - loss: 9.7796e-04\n",
      "Epoch 66/100\n",
      "142/142 [==============================] - 0s 860us/step - loss: 9.5996e-04\n",
      "Epoch 67/100\n",
      "142/142 [==============================] - 0s 868us/step - loss: 9.7142e-04\n",
      "Epoch 68/100\n",
      "142/142 [==============================] - 0s 922us/step - loss: 9.6989e-04\n",
      "Epoch 69/100\n",
      "142/142 [==============================] - 0s 945us/step - loss: 9.6365e-04\n",
      "Epoch 70/100\n",
      "142/142 [==============================] - 0s 983us/step - loss: 9.7070e-04\n",
      "Epoch 71/100\n",
      "142/142 [==============================] - 0s 932us/step - loss: 9.6425e-04\n",
      "Epoch 72/100\n",
      "142/142 [==============================] - 0s 848us/step - loss: 9.6171e-04\n",
      "Epoch 73/100\n",
      "142/142 [==============================] - 0s 862us/step - loss: 9.7279e-04\n",
      "Epoch 74/100\n",
      "142/142 [==============================] - 0s 857us/step - loss: 9.7272e-04\n",
      "Epoch 75/100\n",
      "142/142 [==============================] - 0s 848us/step - loss: 9.7622e-04\n",
      "Epoch 76/100\n",
      "142/142 [==============================] - 0s 874us/step - loss: 9.7199e-04\n",
      "Epoch 77/100\n",
      "142/142 [==============================] - 0s 860us/step - loss: 9.6911e-04\n",
      "Epoch 78/100\n",
      "142/142 [==============================] - 0s 849us/step - loss: 9.6866e-04\n",
      "Epoch 79/100\n",
      "142/142 [==============================] - 0s 890us/step - loss: 9.7335e-04\n",
      "Epoch 80/100\n",
      "142/142 [==============================] - 0s 874us/step - loss: 9.6671e-04\n",
      "Epoch 81/100\n",
      "142/142 [==============================] - 0s 880us/step - loss: 9.6595e-04\n",
      "Epoch 82/100\n",
      "142/142 [==============================] - 0s 849us/step - loss: 9.6385e-04\n",
      "Epoch 83/100\n",
      "142/142 [==============================] - 0s 837us/step - loss: 9.6058e-04\n",
      "Epoch 84/100\n",
      "142/142 [==============================] - 0s 841us/step - loss: 9.5684e-04\n",
      "Epoch 85/100\n",
      "142/142 [==============================] - 0s 862us/step - loss: 9.6337e-04\n",
      "Epoch 86/100\n",
      "142/142 [==============================] - 0s 868us/step - loss: 9.6799e-04\n",
      "Epoch 87/100\n",
      "142/142 [==============================] - 0s 853us/step - loss: 9.6758e-04\n",
      "Epoch 88/100\n",
      "142/142 [==============================] - 0s 846us/step - loss: 9.6283e-04\n",
      "Epoch 89/100\n",
      "142/142 [==============================] - 0s 830us/step - loss: 9.6058e-04\n",
      "Epoch 90/100\n",
      "142/142 [==============================] - 0s 886us/step - loss: 9.7284e-04\n",
      "Epoch 91/100\n",
      "142/142 [==============================] - 0s 827us/step - loss: 9.7069e-04\n",
      "Epoch 92/100\n",
      "142/142 [==============================] - 0s 856us/step - loss: 9.7699e-04\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 831us/step - loss: 9.6946e-04\n",
      "Epoch 94/100\n",
      "142/142 [==============================] - 0s 859us/step - loss: 9.7096e-04\n",
      "Epoch 95/100\n",
      "142/142 [==============================] - 0s 839us/step - loss: 9.6307e-04\n",
      "Epoch 96/100\n",
      "142/142 [==============================] - 0s 846us/step - loss: 9.6748e-04\n",
      "Epoch 97/100\n",
      "142/142 [==============================] - 0s 873us/step - loss: 9.7273e-04\n",
      "Epoch 98/100\n",
      "142/142 [==============================] - 0s 865us/step - loss: 9.7004e-04\n",
      "Epoch 99/100\n",
      "142/142 [==============================] - 0s 844us/step - loss: 9.6428e-04\n",
      "Epoch 100/100\n",
      "142/142 [==============================] - 0s 823us/step - loss: 9.6363e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x65a30a10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input,returns,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzzF0NNfm-OW",
    "outputId": "b9ef96d1-9549-4c29-aee9-933f970a6331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 646us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.0015551017335234533>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(input[4071:])\n",
    "loss=quantile_loss(0.95,returns[4071:],pred)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.2449579824463668>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_denormalized = (pred * (max_values['Close'] - min_values['Close'])) + min_values['Close']\n",
    "returns_denormalized = (returns * (max_values['Close'] - min_values['Close'])) + min_values['Close']\n",
    "loss=quantile_loss(0.96,returns_denormalized[4071:],pred_denormalized)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
