{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "lbu9efRrm8rB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_bFybhox26tc"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLp6mSkQm9ZS",
    "outputId": "14a2d2bd-86fb-496c-b241-26629e4ed6ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "stock='AXISBANK.NS'\n",
    "data = yf.download(stock,'2005-01-01','2023-05-05')\n",
    "data1=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "re200cTwnAnm",
    "outputId": "5ebddc1d-450e-42b2-f95a-e470b37a6438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2005-01-03    0.002702\n",
       "2005-01-04    0.002610\n",
       "2005-01-05    0.001597\n",
       "2005-01-06    0.001764\n",
       "2005-01-07    0.002684\n",
       "                ...   \n",
       "2023-04-27    0.913188\n",
       "2023-04-28    0.890224\n",
       "2023-05-02    0.901652\n",
       "2023-05-03    0.890063\n",
       "2023-05-04    0.896609\n",
       "Name: Adj Close, Length: 4525, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_prices = data['Adj Close']\n",
    "\n",
    "min_value = close_prices.min()\n",
    "max_value = close_prices.max()\n",
    "normalized_data = (close_prices - min_value) / (max_value - min_value)\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close  Adj Close    Volume\n",
      "Date                                                                   \n",
      "2005-01-03  0.001788  0.001671  0.003257  0.003139   0.002702  0.011789\n",
      "2005-01-04  0.003101  0.001886  0.003692  0.003031   0.002610  0.009257\n",
      "2005-01-05  0.002854  0.001446  0.001640  0.001855   0.001597  0.009649\n",
      "2005-01-06  0.001594  0.001457  0.001520  0.002049   0.001764  0.009894\n",
      "2005-01-07  0.000851  0.001864  0.002313  0.003117   0.002684  0.012695\n",
      "...              ...       ...       ...       ...        ...       ...\n",
      "2023-04-27  0.918162  0.914288  0.915852  0.912745   0.913188  0.132671\n",
      "2023-04-28  0.915039  0.914342  0.889957  0.889664   0.890224  0.190839\n",
      "2023-05-02  0.898779  0.899717  0.901466  0.901151   0.901652  0.107415\n",
      "2023-05-03  0.892156  0.889485  0.890391  0.889502   0.890063  0.125293\n",
      "2023-05-04  0.888011  0.889807  0.894137  0.896082   0.896609  0.080938\n",
      "\n",
      "[4525 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "columns_to_normalize = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "min_values = data[columns_to_normalize].min()\n",
    "max_values = data[columns_to_normalize].max()\n",
    "normalized_data = (data[columns_to_normalize] - min_values) / (max_values - min_values)\n",
    "print(normalized_data)\n",
    "data=normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PmtwEW1-_kRv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-03</th>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.011789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-04</th>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.009257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-05</th>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.009649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-06</th>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.009894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-07</th>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.012695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27</th>\n",
       "      <td>0.918162</td>\n",
       "      <td>0.914288</td>\n",
       "      <td>0.915852</td>\n",
       "      <td>0.912745</td>\n",
       "      <td>0.913188</td>\n",
       "      <td>0.132671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28</th>\n",
       "      <td>0.915039</td>\n",
       "      <td>0.914342</td>\n",
       "      <td>0.889957</td>\n",
       "      <td>0.889664</td>\n",
       "      <td>0.890224</td>\n",
       "      <td>0.190839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02</th>\n",
       "      <td>0.898779</td>\n",
       "      <td>0.899717</td>\n",
       "      <td>0.901466</td>\n",
       "      <td>0.901151</td>\n",
       "      <td>0.901652</td>\n",
       "      <td>0.107415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03</th>\n",
       "      <td>0.892156</td>\n",
       "      <td>0.889485</td>\n",
       "      <td>0.890391</td>\n",
       "      <td>0.889502</td>\n",
       "      <td>0.890063</td>\n",
       "      <td>0.125293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04</th>\n",
       "      <td>0.888011</td>\n",
       "      <td>0.889807</td>\n",
       "      <td>0.894137</td>\n",
       "      <td>0.896082</td>\n",
       "      <td>0.896609</td>\n",
       "      <td>0.080938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4525 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close    Volume\n",
       "Date                                                                   \n",
       "2005-01-03  0.001788  0.001671  0.003257  0.003139   0.002702  0.011789\n",
       "2005-01-04  0.003101  0.001886  0.003692  0.003031   0.002610  0.009257\n",
       "2005-01-05  0.002854  0.001446  0.001640  0.001855   0.001597  0.009649\n",
       "2005-01-06  0.001594  0.001457  0.001520  0.002049   0.001764  0.009894\n",
       "2005-01-07  0.000851  0.001864  0.002313  0.003117   0.002684  0.012695\n",
       "...              ...       ...       ...       ...        ...       ...\n",
       "2023-04-27  0.918162  0.914288  0.915852  0.912745   0.913188  0.132671\n",
       "2023-04-28  0.915039  0.914342  0.889957  0.889664   0.890224  0.190839\n",
       "2023-05-02  0.898779  0.899717  0.901466  0.901151   0.901652  0.107415\n",
       "2023-05-03  0.892156  0.889485  0.890391  0.889502   0.890063  0.125293\n",
       "2023-05-04  0.888011  0.889807  0.894137  0.896082   0.896609  0.080938\n",
       "\n",
       "[4525 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "73fqShMpnDN4"
   },
   "outputs": [],
   "source": [
    "returns = np.diff(data['Adj Close'])\n",
    "copyreturns=np.diff(data1['Adj Close'])\n",
    "copyreturns=-copyreturns\n",
    "returns=-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmZHg_p26ahP",
    "outputId": "863d1809-a9dd-434c-bfe3-8d917b951075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4525, 6), (4524,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape,returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMgvQUgA6dIw",
    "outputId": "cc119b57-0440-4688-9ef4-f3b6abc64c88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4524,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcFGmyFC4COW",
    "outputId": "78a22ef4-33bc-4a28-d774-b1b63fbf2934"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8939064173861064"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IwV_2pdNnGx4",
    "outputId": "da362001-3831-41d9-f4f3-ae6878067783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2005-01-03    0.002702\n",
       "2005-01-04    0.002610\n",
       "2005-01-05    0.001597\n",
       "2005-01-06    0.001764\n",
       "2005-01-07    0.002684\n",
       "                ...   \n",
       "2023-04-27    0.913188\n",
       "2023-04-28    0.890224\n",
       "2023-05-02    0.901652\n",
       "2023-05-03    0.890063\n",
       "2023-05-04    0.896609\n",
       "Name: Adj Close, Length: 4525, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5AvfkJoquFc",
    "outputId": "f87d37b9-c191-4a09-a97d-6b9aec246cee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.00019759204628340106, 0.009668438095499244)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(returns)\n",
    "std_dev = np.std(returns)\n",
    "mean,std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcFxz8yIQ9qM",
    "outputId": "f67ab73b-6928-41bd-d852-d4310e93e869"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.28709763e-05,  1.01224483e-03, -1.67156272e-04, ...,\n",
       "       -1.14283354e-02,  1.15892609e-02, -6.54576923e-03])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It97f7V1RXDk",
    "outputId": "a063e301-0f1c-4c9c-9e1c-f68cdb41bf78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08373783, -0.07999809, -0.06792979, ...,  0.06450123,\n",
       "        0.08153718,  0.12803812])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.array(returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "OXFADha_A2lN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "JZwcIuXCzw-q"
   },
   "outputs": [],
   "source": [
    "def quantile_loss(q, y, y_p):\n",
    "        e = y-y_p\n",
    "        return tf.keras.backend.mean(tf.keras.backend.maximum(q*e, (q-1)*e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmdir21AmqMz",
    "outputId": "0c6d448f-cc2a-4fc6-d822-255070cf2f0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4524,), (4524,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=data['Adj Close'][0:-1]\n",
    "input.shape,returns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = 0.95\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(100,1)))\n",
    "model.add(Dropout(0.1)) \n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=lambda y, y_p: quantile_loss(quantile, y, y_p), optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtaQv5dAmt5u",
    "outputId": "351b2428-ca76-47ca-aadd-51a07d843866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "142/142 [==============================] - 3s 2ms/step - loss: 0.0010\n",
      "Epoch 2/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8935e-04\n",
      "Epoch 3/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 4/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 5/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.9219e-04\n",
      "Epoch 6/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7696e-04\n",
      "Epoch 7/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.9608e-04\n",
      "Epoch 8/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 9/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8301e-04\n",
      "Epoch 10/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.9679e-04\n",
      "Epoch 11/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8353e-04\n",
      "Epoch 12/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.8568e-04\n",
      "Epoch 13/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8513e-04\n",
      "Epoch 14/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.9907e-04\n",
      "Epoch 15/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7961e-04\n",
      "Epoch 16/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8167e-04\n",
      "Epoch 17/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.9839e-04\n",
      "Epoch 18/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8614e-04\n",
      "Epoch 19/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.8044e-04\n",
      "Epoch 20/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.9282e-04\n",
      "Epoch 21/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.8294e-04\n",
      "Epoch 22/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6848e-04\n",
      "Epoch 23/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8486e-04\n",
      "Epoch 24/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7661e-04\n",
      "Epoch 25/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8605e-04\n",
      "Epoch 26/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8329e-04\n",
      "Epoch 27/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8263e-04\n",
      "Epoch 28/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7016e-04\n",
      "Epoch 29/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7487e-04\n",
      "Epoch 30/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7795e-04\n",
      "Epoch 31/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7719e-04\n",
      "Epoch 32/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8042e-04\n",
      "Epoch 33/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7918e-04\n",
      "Epoch 34/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8205e-04\n",
      "Epoch 35/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7765e-04\n",
      "Epoch 36/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7718e-04\n",
      "Epoch 37/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7966e-04\n",
      "Epoch 38/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.6915e-04\n",
      "Epoch 39/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7733e-04\n",
      "Epoch 40/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7735e-04\n",
      "Epoch 41/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8677e-04\n",
      "Epoch 42/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.8557e-04\n",
      "Epoch 43/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7536e-04\n",
      "Epoch 44/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7564e-04\n",
      "Epoch 45/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7733e-04\n",
      "Epoch 46/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7671e-04\n",
      "Epoch 47/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8078e-04\n",
      "Epoch 48/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7103e-04\n",
      "Epoch 49/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7468e-04\n",
      "Epoch 50/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8007e-04\n",
      "Epoch 51/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6775e-04\n",
      "Epoch 52/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7453e-04\n",
      "Epoch 53/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7065e-04\n",
      "Epoch 54/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8433e-04\n",
      "Epoch 55/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7442e-04\n",
      "Epoch 56/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7238e-04\n",
      "Epoch 57/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.6720e-04\n",
      "Epoch 58/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.8327e-04\n",
      "Epoch 59/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7372e-04\n",
      "Epoch 60/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.8099e-04\n",
      "Epoch 61/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7991e-04\n",
      "Epoch 62/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7303e-04\n",
      "Epoch 63/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7636e-04\n",
      "Epoch 64/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7293e-04\n",
      "Epoch 65/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6884e-04\n",
      "Epoch 66/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6787e-04\n",
      "Epoch 67/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8347e-04\n",
      "Epoch 68/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8785e-04\n",
      "Epoch 69/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7029e-04\n",
      "Epoch 70/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6851e-04\n",
      "Epoch 71/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6577e-04\n",
      "Epoch 72/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6978e-04\n",
      "Epoch 73/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.8247e-04\n",
      "Epoch 74/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7903e-04\n",
      "Epoch 75/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7542e-04\n",
      "Epoch 76/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7563e-04\n",
      "Epoch 77/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6977e-04\n",
      "Epoch 78/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.6628e-04\n",
      "Epoch 79/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7466e-04\n",
      "Epoch 80/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7042e-04\n",
      "Epoch 81/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7033e-04\n",
      "Epoch 82/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7847e-04\n",
      "Epoch 83/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7438e-04\n",
      "Epoch 84/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7098e-04\n",
      "Epoch 85/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7107e-04\n",
      "Epoch 86/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6452e-04\n",
      "Epoch 87/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7299e-04\n",
      "Epoch 88/100\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 9.7559e-04\n",
      "Epoch 89/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6749e-04\n",
      "Epoch 90/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6796e-04\n",
      "Epoch 91/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7197e-04\n",
      "Epoch 92/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7704e-04\n",
      "Epoch 93/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7436e-04\n",
      "Epoch 94/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6923e-04\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7001e-04\n",
      "Epoch 96/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6552e-04\n",
      "Epoch 97/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7424e-04\n",
      "Epoch 98/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.7929e-04\n",
      "Epoch 99/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6888e-04\n",
      "Epoch 100/100\n",
      "142/142 [==============================] - 0s 2ms/step - loss: 9.6822e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7427e10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input,returns,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzzF0NNfm-OW",
    "outputId": "b9ef96d1-9549-4c29-aee9-933f970a6331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.0015609379515205506>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model.predict(input[4071:])\n",
    "loss=quantile_loss(0.95,returns[4071:],pred)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.2406025484279928>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_denormalized = (pred * (max_values['Close'] - min_values['Close'])) + min_values['Close']\n",
    "returns_denormalized = (returns * (max_values['Close'] - min_values['Close'])) + min_values['Close']\n",
    "loss=quantile_loss(0.96,returns_denormalized[4071:],pred_denormalized)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
